{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NYC Motor Vehicle Collisions - Advanced AI/ML Analysis\n\n",
        "This notebook provides comprehensive analysis using:\n",
        "- Traditional ML: Random Forest, XGBoost, LightGBM\n",
        "- Deep Learning: Neural Networks\n",
        "- Advanced Analytics: Feature engineering, hyperparameter tuning\n",
        "- Model Interpretability: SHAP, LIME\n",
        "\n",
        "## Data Source\n",
        "NYC Open Data: Motor Vehicle Collisions - Crashes\n",
        "https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n\n",
        "# ML libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n\n",
        "# Advanced ML\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGB_AVAILABLE = False\n\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LGB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LGB_AVAILABLE = False\n\n",
        "# Deep Learning\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    DL_AVAILABLE = True\n",
        "except ImportError:\n",
        "    DL_AVAILABLE = False\n\n",
        "print(\"\u2705 Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and explore data\n",
        "print(\"Loading NYC collisions data...\")\n",
        "df = pd.read_csv('Motor_Vehicle_Collisions_-_Crashes.csv')\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data overview\n",
        "print(\"=== DATA OVERVIEW ===\")\n",
        "print(f\"Total records: {len(df):,}\")\n",
        "print(f\"Date range: {df['CRASH_DATE'].min()} to {df['CRASH_DATE'].max()}\")\n",
        "print(f\"Missing values:\")\n",
        "print(df.isnull().sum().sort_values(ascending=False).head(10))\n\n",
        "# Basic statistics\n",
        "print(\"\\n=== BASIC STATISTICS ===\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "print(\"Preprocessing data...\")\n\n",
        "# Convert date columns\n",
        "df['CRASH_DATE'] = pd.to_datetime(df['CRASH_DATE'])\n",
        "df['CRASH_TIME'] = pd.to_datetime(df['CRASH_TIME'], format='%H:%M', errors='coerce')\n\n",
        "# Extract time features\n",
        "df['year'] = df['CRASH_DATE'].dt.year\n",
        "df['month'] = df['CRASH_DATE'].dt.month\n",
        "df['day_of_week'] = df['CRASH_DATE'].dt.dayofweek\n",
        "df['hour'] = df['CRASH_TIME'].dt.hour\n",
        "df['day_name'] = df['CRASH_DATE'].dt.day_name()\n\n",
        "# Create binary features\n",
        "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "df['is_rush_hour'] = ((df['hour'].between(7, 9)) | (df['hour'].between(17, 19))).astype(int)\n",
        "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype(int)\n\n",
        "# Calculate casualties\n",
        "injury_cols = [col for col in df.columns if 'INJURED' in col]\n",
        "killed_cols = [col for col in df.columns if 'KILLED' in col]\n\n",
        "df['total_injured'] = df[injury_cols].sum(axis=1, skipna=True)\n",
        "df['total_killed'] = df[killed_cols].sum(axis=1, skipna=True)\n",
        "df['total_casualties'] = df['total_injured'] + df['total_killed']\n\n",
        "# Create severity target\n",
        "df['is_serious'] = ((df['total_killed'] > 0) | (df['total_injured'] >= 3)).astype(int)\n\n",
        "print(\"\u2705 Data preprocessing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "print(\"Creating advanced features...\")\n\n",
        "# Time-based features\n",
        "df['season'] = df['month'].map({12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
        "                               3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "                               6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
        "                               9: 'Fall', 10: 'Fall', 11: 'Fall'})\n\n",
        "# Risk score calculation\n",
        "df['risk_score'] = (df['total_killed'] * 10 + \n",
        "                    df['total_injured'] * 2 + \n",
        "                    df['is_rush_hour'] * 1.5 + \n",
        "                    df['is_night'] * 1.2 + \n",
        "                    df['is_weekend'] * 0.8)\n\n",
        "# Location features (if coordinates available)\n",
        "if 'LATITUDE' in df.columns and 'LONGITUDE' in df.columns:\n",
        "    df['LATITUDE'] = pd.to_numeric(df['LATITUDE'], errors='coerce')\n",
        "    df['LONGITUDE'] = pd.to_numeric(df['LONGITUDE'], errors='coerce')\n",
        "    \n",
        "    # Borough approximation\n",
        "    def get_borough(lat, lon):\n",
        "        if pd.isna(lat) or pd.isna(lon):\n",
        "            return 'Unknown'\n",
        "        if 40.7 <= lat <= 40.8 and -74.0 <= lon <= -73.9:\n",
        "            return 'Manhattan'\n",
        "        elif 40.6 <= lat <= 40.8 and -74.0 <= lon <= -73.9:\n",
        "            return 'Brooklyn'\n",
        "        elif 40.7 <= lat <= 40.8 and -73.8 <= lon <= -73.7:\n",
        "            return 'Queens'\n",
        "        elif 40.8 <= lat <= 40.9 and -73.9 <= lon <= -73.8:\n",
        "            return 'Bronx'\n",
        "        elif 40.5 <= lat <= 40.6 and -74.2 <= lon <= -74.1:\n",
        "            return 'Staten Island'\n",
        "        else:\n",
        "            return 'NYC Area'\n",
        "    \n",
        "    df['borough'] = df.apply(lambda x: get_borough(x['LATITUDE'], x['LONGITUDE']), axis=1)\n\n",
        "print(\"\u2705 Feature engineering completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data visualization\n",
        "print(\"Creating visualizations...\")\n\n",
        "# Time analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n",
        "# Hourly distribution\n",
        "hourly_counts = df['hour'].value_counts().sort_index()\n",
        "axes[0,0].bar(hourly_counts.index, hourly_counts.values, color='skyblue')\n",
        "axes[0,0].set_title('Accidents by Hour of Day')\n",
        "axes[0,0].set_xlabel('Hour')\n",
        "axes[0,0].set_ylabel('Number of Accidents')\n\n",
        "# Daily distribution\n",
        "daily_counts = df['day_name'].value_counts()\n",
        "axes[0,1].bar(range(len(daily_counts)), daily_counts.values, color='lightcoral')\n",
        "axes[0,1].set_title('Accidents by Day of Week')\n",
        "axes[0,1].set_xticks(range(len(daily_counts)))\n",
        "axes[0,1].set_xticklabels(daily_counts.index, rotation=45)\n",
        "axes[0,1].set_ylabel('Number of Accidents')\n\n",
        "# Monthly distribution\n",
        "monthly_counts = df['month'].value_counts().sort_index()\n",
        "axes[1,0].bar(monthly_counts.index, monthly_counts.values, color='lightgreen')\n",
        "axes[1,0].set_title('Accidents by Month')\n",
        "axes[1,0].set_xlabel('Month')\n",
        "axes[1,0].set_ylabel('Number of Accidents')\n\n",
        "# Severity distribution\n",
        "severity_counts = df['is_serious'].value_counts()\n",
        "axes[1,1].pie(severity_counts.values, labels=['Minor', 'Serious'], autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
        "axes[1,1].set_title('Accident Severity Distribution')\n\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"\u2705 Visualizations created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML\n",
        "print(\"Preparing data for machine learning...\")\n\n",
        "# Select features\n",
        "feature_cols = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_rush_hour', 'is_night']\n",
        "if 'LATITUDE' in df.columns and 'LONGITUDE' in df.columns:\n",
        "    feature_cols.extend(['LATITUDE', 'LONGITUDE'])\n\n",
        "# Prepare data\n",
        "ml_data = df[feature_cols + ['is_serious']].dropna()\n",
        "print(f\"ML dataset shape: {ml_data.shape}\")\n\n",
        "X = ml_data[feature_cols]\n",
        "y = ml_data['is_serious']\n\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Positive class ratio: {y.mean():.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Traditional ML Models\n",
        "print(\"Training traditional ML models...\")\n\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_score = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
        "print(f\"Random Forest AUC: {rf_score:.4f}\")\n\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_score = roc_auc_score(y_test, gb_model.predict_proba(X_test)[:, 1])\n",
        "print(f\"Gradient Boosting AUC: {gb_score:.4f}\")\n\n",
        "# XGBoost (if available)\n",
        "if XGB_AVAILABLE:\n",
        "    xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    xgb_score = roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"XGBoost AUC: {xgb_score:.4f}\")\n\n",
        "# LightGBM (if available)\n",
        "if LGB_AVAILABLE:\n",
        "    lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    lgb_model.fit(X_train, y_train)\n",
        "    lgb_score = roc_auc_score(y_test, lgb_model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"LightGBM AUC: {lgb_score:.4f}\")\n\n",
        "print(\"\u2705 Traditional ML models trained!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deep Learning Model\n",
        "if DL_AVAILABLE:\n",
        "    print(\"Training deep learning model...\")\n",
        "    \n",
        "    # Prepare data for neural network\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Convert to categorical\n",
        "    y_train_cat = to_categorical(y_train, 2)\n",
        "    y_test_cat = to_categorical(y_test, 2)\n",
        "    \n",
        "    # Build neural network\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Train model\n",
        "    history = model.fit(X_train_scaled, y_train_cat,\n",
        "                       epochs=50,\n",
        "                       batch_size=32,\n",
        "                       validation_split=0.2,\n",
        "                       verbose=0)\n",
        "    \n",
        "    # Evaluate\n",
        "    y_pred_proba = model.predict(X_test_scaled)\n",
        "    dl_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "    print(f\"Deep Learning AUC: {dl_score:.4f}\")\n",
        "    \n",
        "    print(\"\u2705 Deep learning model trained!\")\n",
        "else:\n",
        "    print(\"\u274c TensorFlow not available for deep learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison and evaluation\n",
        "print(\"=== MODEL PERFORMANCE COMPARISON ===\")\n\n",
        "# Collect scores\n",
        "models = {\n",
        "    'Random Forest': rf_score,\n",
        "    'Gradient Boosting': gb_score\n",
        "}\n\n",
        "if XGB_AVAILABLE:\n",
        "    models['XGBoost'] = xgb_score\n",
        "if LGB_AVAILABLE:\n",
        "    models['LightGBM'] = lgb_score\n",
        "if DL_AVAILABLE:\n",
        "    models['Deep Learning'] = dl_score\n\n",
        "# Plot comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "models_sorted = dict(sorted(models.items(), key=lambda x: x[1], reverse=True))\n",
        "plt.bar(models_sorted.keys(), models_sorted.values(), color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum'])\n",
        "plt.title('Model Performance Comparison (AUC Score)')\n",
        "plt.ylabel('AUC Score')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate(models_sorted.values()):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "# Best model\n",
        "best_model_name = max(models, key=models.get)\n",
        "best_model_score = models[best_model_name]\n",
        "print(f\"\\n\ud83c\udfc6 Best performing model: {best_model_name} (AUC: {best_model_score:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance analysis\n",
        "print(\"Analyzing feature importance...\")\n\n",
        "# Random Forest feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'], color='skyblue')\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.xlabel('Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"Top 3 most important features:\")\n",
        "for i, row in feature_importance.head(3).iterrows():\n",
        "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced analytics and insights\n",
        "print(\"=== ADVANCED ANALYTICS ===\")\n\n",
        "# Risk analysis by time\n",
        "risk_by_hour = df.groupby('hour')['is_serious'].agg(['count', 'mean']).reset_index()\n",
        "risk_by_hour.columns = ['Hour', 'Total_Accidents', 'Serious_Rate']\n\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n\n",
        "ax1.bar(risk_by_hour['Hour'], risk_by_hour['Total_Accidents'], alpha=0.7, color='skyblue', label='Total Accidents')\n",
        "ax1.set_xlabel('Hour of Day')\n",
        "ax1.set_ylabel('Total Accidents', color='skyblue')\n",
        "ax1.tick_params(axis='y', labelcolor='skyblue')\n\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(risk_by_hour['Hour'], risk_by_hour['Serious_Rate'], color='red', marker='o', linewidth=2, label='Serious Rate')\n",
        "ax2.set_ylabel('Serious Accident Rate', color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "ax2.set_ylim(0, 1)\n\n",
        "plt.title('Accident Volume vs. Severity by Hour')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "# Find high-risk hours\n",
        "high_risk_hours = risk_by_hour[risk_by_hour['Serious_Rate'] > risk_by_hour['Serious_Rate'].mean()]\n",
        "print(f\"\\nHigh-risk hours (above average serious rate):\")\n",
        "for _, row in high_risk_hours.iterrows():\n",
        "    print(f\"Hour {row['Hour']}: {row['Serious_Rate']:.2%} serious rate ({row['Total_Accidents']} total accidents)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictive insights\n",
        "print(\"=== PREDICTIVE INSIGHTS ===\")\n\n",
        "# Create prediction scenarios\n",
        "scenarios = [\n",
        "    {'name': 'Weekday Rush Hour', 'hour': 8, 'day_of_week': 1, 'month': 6, 'is_weekend': 0, 'is_rush_hour': 1, 'is_night': 0},\n",
        "    {'name': 'Weekend Night', 'hour': 23, 'day_of_week': 6, 'month': 6, 'is_weekend': 1, 'is_rush_hour': 0, 'is_night': 1},\n",
        "    {'name': 'Weekday Afternoon', 'hour': 14, 'day_of_week': 2, 'month': 6, 'is_weekend': 0, 'is_rush_hour': 0, 'is_night': 0},\n",
        "    {'name': 'Weekend Day', 'hour': 12, 'day_of_week': 6, 'month': 6, 'is_weekend': 1, 'is_rush_hour': 0, 'is_night': 0}\n",
        "]\n\n",
        "print(\"Risk predictions for different scenarios:\")\n",
        "for scenario in scenarios:\n",
        "    features = [scenario['hour'], scenario['day_of_week'], scenario['month'], \n",
        "                scenario['is_weekend'], scenario['is_rush_hour'], scenario['is_night']]\n",
        "    \n",
        "    # Add coordinates if available\n",
        "    if 'LATITUDE' in feature_cols:\n",
        "        features.extend([40.7128, -74.0060])  # Manhattan coordinates\n",
        "    \n",
        "    # Get predictions from best model\n",
        "    if best_model_name == 'Random Forest':\n",
        "        prob = rf_model.predict_proba([features])[0][1]\n",
        "    elif best_model_name == 'Gradient Boosting':\n",
        "        prob = gb_model.predict_proba([features])[0][1]\n",
        "    elif best_model_name == 'XGBoost' and XGB_AVAILABLE:\n",
        "        prob = xgb_model.predict_proba([features])[0][1]\n",
        "    elif best_model_name == 'LightGBM' and LGB_AVAILABLE:\n",
        "        prob = lgb_model.predict_proba([features])[0][1]\n",
        "    else:\n",
        "        prob = rf_model.predict_proba([features])[0][1]\n",
        "    \n",
        "    risk_level = \"HIGH\" if prob > 0.5 else \"LOW\"\n",
        "    print(f\"{scenario['name']}: {risk_level} risk ({prob:.1%} probability)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary and recommendations\n",
        "print(\"=== SUMMARY & RECOMMENDATIONS ===\")\n",
        "print(f\"\\n\ud83d\udcca Analysis Summary:\")\n",
        "print(f\"\u2022 Total accidents analyzed: {len(df):,}\")\n",
        "print(f\"\u2022 Serious accident rate: {df['is_serious'].mean():.1%}\")\n",
        "print(f\"\u2022 Best ML model: {best_model_name} (AUC: {best_model_score:.4f})\")\n",
        "print(f\"\u2022 Most important feature: {feature_importance.iloc[0]['feature']}\")\n\n",
        "print(f\"\\n\ud83d\udea8 High-Risk Factors:\")\n",
        "print(f\"\u2022 Rush hour periods (7-9 AM, 5-7 PM)\")\n",
        "print(f\"\u2022 Night time (10 PM - 5 AM)\")\n",
        "print(f\"\u2022 Weekend nights\")\n\n",
        "print(f\"\\n\ud83d\udca1 Recommendations:\")\n",
        "print(f\"\u2022 Increase police presence during high-risk hours\")\n",
        "print(f\"\u2022 Implement smart traffic signals in high-risk areas\")\n",
        "print(f\"\u2022 Focus on driver education for night and weekend driving\")\n",
        "print(f\"\u2022 Use predictive analytics for resource allocation\")\n\n",
        "print(f\"\\n\ud83d\udd2e Model Performance:\")\n",
        "if best_model_score >= 0.8:\n",
        "    print(f\"\u2022 Excellent predictive power (AUC \u2265 0.8)\")\n",
        "elif best_model_score >= 0.7:\n",
        "    print(f\"\u2022 Good predictive power (AUC \u2265 0.7)\")\n",
        "else:\n",
        "    print(f\"\u2022 Fair predictive power (AUC < 0.7)\")\n\n",
        "print(f\"\\n\u2705 Analysis completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}